knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE,
error = FALSE,
comment = NA
)
library(readr)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ISLR)
library(glmnet)
library(tidyverse)
library(caret)
library(corrplot)
df <- read_csv("Spotify-2000.csv", col_select = -c("Index"))
numeric_df <- df %>% select(where(is.numeric))
cor_matrix <- cor(numeric_df, use = "complete.obs")
cor_matrix <- round(cor_matrix, 2)
corrplot(cor_matrix, method = "color", type = "upper",
tl.col = "black", tl.srt = 45, addCoef.col = "black") #, title = "Figure 1. Correlation Matrix"
df_new <- df %>%
rename(
"BeatsPerMinute" = "Beats Per Minute (BPM)",
"Loudness" = "Loudness (dB)",
"Length" = "Length (Duration)"
)
# df_new <- df %>%
#   select(-c("Beats Per Minute (BPM)",
#          "Loudness (dB)",
#          "Length (Duration)",
#          "Valence",
#          "Acousticness"))
head(df_new, 5)
spotify.ex1 <- ggplot(data = df_new, mapping = aes(x = Year, y = Popularity)) +
geom_point(size = 1.5, alpha = 1) +
geom_smooth(se = F, na.rm = T, method = "lm") +
labs(title = "Popularity through the years") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
spotify.ex2 <- ggplot(data = df_new, mapping = aes(x = Year, y = Popularity,
colour = Danceability)) +
geom_hex() +
scale_fill_gradient(low = "yellow", high = "black")
labs(title = "Popularity through the years") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
spotify.ex1
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE,
error = FALSE,
comment = NA
)
library(readr)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ISLR)
library(glmnet)
library(tidyverse)
library(caret)
library(corrplot)
str(Spotify) # check the structure of the dataset
colSums(is.na(Spotify)) # check for missing values in the dataset.
# The dataset has no missing values.
# We then clean the dataset by renaming the columns for clarity and converting the relevant columns to numeric.
# Check which columns are not clean numerics
glimpse(Spotify)
# Cleaned version (only mutate numeric columns that are truly numeric)
spotify_data <- Spotify %>%
rename(
BPM = `Beats.Per.Minute..BPM.`,
Loudness = `Loudness..dB.`,
Genre = `Top.Genre`,
Length = `Length..Duration.`
) %>%
mutate(
BPM = as.numeric(BPM),
Energy = as.numeric(Energy),
Danceability = as.numeric(Danceability),
Loudness = as.numeric(Loudness),
Valence = as.numeric(Valence),
Length = as.numeric(Length),
Acousticness = as.numeric(Acousticness),
Speechiness = as.numeric(Speechiness),
Liveness = as.numeric(Liveness),
Popularity = as.numeric(Popularity),
Year = as.numeric(Year)
)
set.seed(123)
Spotify <- read.csv("Spotify-2000.csv")
colnames(Spotify)
str(Spotify) # check the structure of the dataset
colSums(is.na(Spotify)) # check for missing values in the dataset.
# The dataset has no missing values.
# We then clean the dataset by renaming the columns for clarity and converting the relevant columns to numeric.
# Check which columns are not clean numerics
glimpse(Spotify)
# Cleaned version (only mutate numeric columns that are truly numeric)
spotify_data <- Spotify %>%
rename(
BPM = `Beats.Per.Minute..BPM.`,
Loudness = `Loudness..dB.`,
Genre = `Top.Genre`,
Length = `Length..Duration.`
) %>%
mutate(
BPM = as.numeric(BPM),
Energy = as.numeric(Energy),
Danceability = as.numeric(Danceability),
Loudness = as.numeric(Loudness),
Valence = as.numeric(Valence),
Length = as.numeric(Length),
Acousticness = as.numeric(Acousticness),
Speechiness = as.numeric(Speechiness),
Liveness = as.numeric(Liveness),
Popularity = as.numeric(Popularity),
Year = as.numeric(Year)
)
# Plot histogram of popularity
ggplot(spotify_data, aes(x = Popularity)) +
geom_histogram(binwidth = 5, fill = "darkgreen", color = "white", alpha = 0.8) +
labs(
title = "Distribution of Track Popularity",
x = "Popularity Score",
y = "Count of Tracks"
) +
theme_minimal()
# Plot average popularity by year with linear model
spotify_data %>%
group_by(Year) %>%
summarise(Avg_Popularity = mean(Popularity, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = Avg_Popularity)) +
geom_line(color = "steelblue", size = 1) +
geom_smooth(method = "lm", color = "blue", fill = "lightblue", se = TRUE) +
labs(
title = "Average Track Popularity Over Years",
x = "Release Year",
y = "Average Popularity"
) +
theme_minimal()
# Select numeric variables
num_data <- spotify_data %>%
select(where(is.numeric))
# Compute correlation matrix
cor_matrix <- cor(num_data, use = "complete.obs")
# Plot heatmap
corrplot(cor_matrix, method = "color", type = "lower",
tl.col = "black", tl.srt = 45, number.cex = 0.7,
addCoef.col = "black", diag = FALSE)
#get rid of all NA values
spotify_data <- na.omit(spotify_data)
#creating train, test and valid datasets
train_index <- createDataPartition(spotify_data$Popularity, p = 0.5, list = FALSE)
df_train <- spotify_data[train_index, ]
remaining <- spotify_data[-train_index, ]
valid_index <- createDataPartition(remaining$Popularity, p = 0.6, list = FALSE)
df_valid <- remaining[valid_index, ]
df_test <- remaining[-valid_index, ]
#graph to make sure of distribution
df_train$Set <- "Train"
df_valid$Set <- "Validation"
df_test$Set <- "Test"
combined <- bind_rows(df_train, df_valid, df_test)
ggplot(combined, aes(x = Popularity, fill = Set)) +
geom_density(alpha = 0.4) +
theme_minimal()
#some preparations: functions for formula generation and MSE calculation
source("generate_formulas.R")
lm_mse <- function(formula, train_data, valid_data) {
y_name <- as.character(formula)[2]
y_true <- valid_data[[y_name]]
lm_fit <- lm(formula, train_data)
y_pred <- predict(lm_fit, newdata = valid_data)
mean((y_true - y_pred)^2)
}
# identifying predictors
df_pred <- spotify_data %>% select(-c("Title", "Artist", "Genre", "Popularity", "Index"))
predictors <- colnames(df_pred)
# assessing the best model
top_formulas <- list()
top_mses <- numeric()
for (p in 1:length(predictors)) {
forms <- generate_formulas(p = p, x_vars = predictors, y_var = "Popularity")
mses <- rep(0, length(forms))
for (i in 1:length(forms)) {
mses[i] <- lm_mse(as.formula(forms[i]), df_train, df_valid)
}
top_formulas[[p]] <- forms[which.min(mses)]
top_mses[p] <- mses[which.min(mses)]
}
#print("Top formulas for each number of predictors")
#top_formulas
print(paste("Best overall formula based on MSE (MSE =", round(min(top_mses), digits = 2), ")"))
best_model <- top_formulas[[which.min(top_mses)]]
best_model
#calculate test MSE
mse <- function(actual, predicted) {
mean((actual - predicted)^2)
}
train_valid <- bind_rows(df_train, df_valid)
best_model <- lm(best_model, data = train_valid)
pred_test <- predict(best_model, newdata = df_test)
test_mse <- mse(df_test$Popularity, pred_test)
print(paste("Test MSE =", round(test_mse, digits = 2)))
results_df <- data.frame(
Actual = df_test$Popularity,
Predicted = pred_test
)
ggplot(results_df, aes(x = Predicted, y = Actual)) +
geom_point(alpha = 0.6, size = 2) +
geom_abline(slope = 1, intercept = 0, color = "red", size = 1) +
labs(title = "Predicted vs Actual Popularity",
x = "Predicted Popularity",
y = "Actual Popularity") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
